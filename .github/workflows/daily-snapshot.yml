name: Daily Metrics Snapshot
# ============================================================================
# METRICS SNAPSHOT WORKFLOW
# See: .data/METRICS_SPEC.md for complete documentation
#
# This workflow captures daily metrics from npm, GitHub, and Dev.to APIs.
#
# KEY CONCEPTS:
# - Cumulative totals: totalDownloads, views, contributions, commits, reactions, comments
# - Point-in-time: stars, followers, packageCount, plugins, rules, articles
# - Daily deltas: Calculated as (today's value - MOST RECENT previous snapshot)
#   - If no previous snapshot exists: delta = 0
#   - If delta is negative (API inconsistency): delta = 0
#
# RESILIENCE:
# - Runs 3 times daily (6 AM, 12 PM, 6 PM UTC) as retry attempts
# - If today's snapshot already exists, it gets overwritten (upsert behavior)
# - Uses most recent previous snapshot for delta (handles missed days)
# - API calls have retry logic with exponential backoff
#
# OUTPUT FILES:
# - .data/snapshots/YYYY-MM-DD.json (individual backup)
# - .data/snapshots/aggregation.json (combined for fast loading, max 365 days)
#
# REQUIRED SECRETS:
# - DEVTO_API_KEY: Dev.to API key
# - CODECOV_TOKEN: Codecov API token
# - GITHUB_TOKEN: Auto-provided
# ============================================================================

on:
  schedule:
    # Run 3 times daily as retry mechanism (if first fails, second/third will capture)
    - cron: "0 6 * * *" # 6:00 AM UTC (primary)
    - cron: "0 12 * * *" # 12:00 PM UTC (retry 1)
    - cron: "0 18 * * *" # 6:00 PM UTC (retry 2)
  workflow_dispatch: # Allow manual trigger

permissions:
  contents: write

jobs:
  snapshot:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install dependencies
        run: npm install -g node-fetch

      - name: Capture Metrics Snapshot
        env:
          DEVTO_API_KEY: ${{ secrets.DEVTO_API_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}
        run: |
          DATE=$(date +%Y-%m-%d)
          mkdir -p .data/snapshots

          echo "=========================================="
          echo "ðŸ“Š Capturing metrics for $DATE"
          echo "=========================================="

          # ============================================================
          # STEP 1: Find MOST RECENT previous snapshot for delta calculation
          # This handles missed days - we always compare to the last available snapshot
          # ============================================================
          PREV_FILE=""
          for i in 1 2 3 4 5 6 7; do
            CHECK_DATE=$(date -d "$i days ago" +%Y-%m-%d 2>/dev/null || date -v-${i}d +%Y-%m-%d)
            if [ -f ".data/snapshots/$CHECK_DATE.json" ]; then
              PREV_FILE=".data/snapshots/$CHECK_DATE.json"
              echo "ðŸ“ Found previous snapshot from $CHECK_DATE"
              break
            fi
          done

          HAS_PREVIOUS=false
          if [ -n "$PREV_FILE" ] && [ -f "$PREV_FILE" ]; then
            HAS_PREVIOUS=true
            PREV_DOWNLOADS=$(jq '.npm.totalDownloads // 0' "$PREV_FILE")
            PREV_VIEWS=$(jq '.devto.views // 0' "$PREV_FILE")
            PREV_REACTIONS=$(jq '.devto.reactions // 0' "$PREV_FILE")
            PREV_COMMENTS=$(jq '.devto.comments // 0' "$PREV_FILE")
            PREV_CONTRIBUTIONS=$(jq '.github.contributions // 0' "$PREV_FILE")
            PREV_COMMITS=$(jq '.github.commits // 0' "$PREV_FILE")
            PREV_FOLLOWERS=$(jq '(.github.followers // 0) + (.devto.followers // 0)' "$PREV_FILE")
          else
            # No previous day - can't calculate real deltas
            PREV_DOWNLOADS=0
            PREV_VIEWS=0
            PREV_REACTIONS=0
            PREV_COMMENTS=0
            PREV_CONTRIBUTIONS=0
            PREV_COMMITS=0
            PREV_FOLLOWERS=0
          fi

          # ============================================================
          # Helper: curl with retry (3 attempts, exponential backoff)
          # ============================================================
          curl_retry() {
            local url="$1"
            local headers="$2"
            local max_attempts=3
            local attempt=1
            local wait=2
            while [ $attempt -le $max_attempts ]; do
              if [ -n "$headers" ]; then
                result=$(curl -s -H "$headers" "$url")
              else
                result=$(curl -s "$url")
              fi
              if [ -n "$result" ] && [ "$result" != "null" ] && ! echo "$result" | grep -q '"error"'; then
                echo "$result"
                return 0
              fi
              echo "Retry $attempt/$max_attempts for $url" >&2
              sleep $wait
              wait=$((wait * 2))
              attempt=$((attempt + 1))
            done
            echo "{}"  # Return empty object on failure
          }

          # ============================================================
          # STEP 2: Fetch npm data (packages + downloads)
          # Excludes: eslint-plugin-mcp, eslint-plugin-llm-*, @forge-js/*
          # ============================================================
          NPM_RESULT=$(curl_retry "https://registry.npmjs.org/-/v1/search?text=maintainer:ofriperetz&size=100")

          # Excluded packages (matches NPM_CONFIG.excludedPackages and excludedPrefixes)
          EXCLUDED_PACKAGES="eslint-plugin-mcp eslint-plugin-llm-optimized eslint-plugin-llm eslint-plugin-mcp-optimized"
          EXCLUDED_PREFIX="@forge-js/"

          # Filter and count packages
          PACKAGE_COUNT=0
          TOTAL_DOWNLOADS=0
          for pkg in $(echo $NPM_RESULT | jq -r '.objects[].package.name'); do
            # Check if package should be excluded
            is_excluded=false
            for excluded in $EXCLUDED_PACKAGES; do
              if [ "$pkg" = "$excluded" ]; then
                is_excluded=true
                break
              fi
            done
            # Check prefix exclusion
            if [[ "$pkg" == $EXCLUDED_PREFIX* ]]; then
              is_excluded=true
            fi
            
            if [ "$is_excluded" = "false" ]; then
              PACKAGE_COUNT=$((PACKAGE_COUNT + 1))
              DOWNLOADS=$(curl -s "https://api.npmjs.org/downloads/point/last-month/$pkg" | jq '.downloads // 0')
              TOTAL_DOWNLOADS=$((TOTAL_DOWNLOADS + DOWNLOADS))
            fi
          done

          # ============================================================
          # STEP 3: Fetch GitHub data (stars, followers, contributions)
          # Target repos: ofri-peretz/ofriperetz-dev, ofri-peretz/eslint
          # ============================================================
          GH_USER=$(curl -s -H "Authorization: Bearer $GITHUB_TOKEN" "https://api.github.com/users/ofri-peretz")
          GH_FOLLOWERS=$(echo $GH_USER | jq '.followers // 0')

          # Get stars only from these two specific repos
          REPO1=$(curl -s -H "Authorization: Bearer $GITHUB_TOKEN" "https://api.github.com/repos/ofri-peretz/ofriperetz-dev")
          REPO2=$(curl -s -H "Authorization: Bearer $GITHUB_TOKEN" "https://api.github.com/repos/ofri-peretz/eslint")
          STARS1=$(echo $REPO1 | jq '.stargazers_count // 0')
          STARS2=$(echo $REPO2 | jq '.stargazers_count // 0')
          GH_STARS=$((STARS1 + STARS2))

          # Fetch GitHub contributions via GraphQL
          GH_CONTRIBUTIONS_RESPONSE=$(curl -s -X POST \
            -H "Authorization: Bearer $GITHUB_TOKEN" \
            -H "Content-Type: application/json" \
            -d '{"query": "query { user(login: \"ofri-peretz\") { contributionsCollection { totalCommitContributions contributionCalendar { totalContributions } } } }"}' \
            https://api.github.com/graphql)
          GH_CONTRIBUTIONS=$(echo $GH_CONTRIBUTIONS_RESPONSE | jq '.data.user.contributionsCollection.contributionCalendar.totalContributions // 0')
          GH_COMMITS=$(echo $GH_CONTRIBUTIONS_RESPONSE | jq '.data.user.contributionsCollection.totalCommitContributions // 0')

          # ============================================================
          # STEP 4: Fetch Dev.to data (articles, views, reactions)
          # Requires DEVTO_API_KEY secret
          # ============================================================
          DEVTO_FOLLOWERS=$(curl -s -H "api-key: $DEVTO_API_KEY" "https://dev.to/api/followers/users?per_page=1000" | jq 'length')
          DEVTO_ARTICLES=$(curl -s -H "api-key: $DEVTO_API_KEY" "https://dev.to/api/articles/me/all?per_page=1000")
          DEVTO_ARTICLE_COUNT=$(echo $DEVTO_ARTICLES | jq 'length')
          DEVTO_VIEWS=$(echo $DEVTO_ARTICLES | jq '[.[].page_views_count] | add // 0')
          DEVTO_REACTIONS=$(echo $DEVTO_ARTICLES | jq '[.[].positive_reactions_count] | add // 0')
          DEVTO_COMMENTS=$(echo $DEVTO_ARTICLES | jq '[.[].comments_count] | add // 0')

          # ============================================================
          # STEP 5: Calculate daily deltas
          # Formula: DAILY_X = TODAY_X - YESTERDAY_X
          # If no previous day or negative delta: set to 0
          # ============================================================
          TOTAL_FOLLOWERS=$((GH_FOLLOWERS + DEVTO_FOLLOWERS))

          if [ "$HAS_PREVIOUS" = "true" ]; then
            # Calculate actual deltas from previous day
            DAILY_DOWNLOADS=$((TOTAL_DOWNLOADS - PREV_DOWNLOADS))
            DAILY_VIEWS=$((DEVTO_VIEWS - PREV_VIEWS))
            DAILY_REACTIONS=$((DEVTO_REACTIONS - PREV_REACTIONS))
            DAILY_COMMENTS=$((DEVTO_COMMENTS - PREV_COMMENTS))
            DAILY_CONTRIBUTIONS=$((GH_CONTRIBUTIONS - PREV_CONTRIBUTIONS))
            DAILY_COMMITS=$((GH_COMMITS - PREV_COMMITS))
            DAILY_FOLLOWERS=$((TOTAL_FOLLOWERS - PREV_FOLLOWERS))
            
            # Ensure deltas are not negative (in case of API inconsistency)
            [ $DAILY_DOWNLOADS -lt 0 ] && DAILY_DOWNLOADS=0
            [ $DAILY_VIEWS -lt 0 ] && DAILY_VIEWS=0
            [ $DAILY_REACTIONS -lt 0 ] && DAILY_REACTIONS=0
            [ $DAILY_COMMENTS -lt 0 ] && DAILY_COMMENTS=0
            [ $DAILY_CONTRIBUTIONS -lt 0 ] && DAILY_CONTRIBUTIONS=0
            [ $DAILY_COMMITS -lt 0 ] && DAILY_COMMITS=0
            [ $DAILY_FOLLOWERS -lt 0 ] && DAILY_FOLLOWERS=0
          else
            # First day - no previous data to compare, set deltas to 0
            DAILY_DOWNLOADS=0
            DAILY_VIEWS=0
            DAILY_REACTIONS=0
            DAILY_COMMENTS=0
            DAILY_CONTRIBUTIONS=0
            DAILY_COMMITS=0
            DAILY_FOLLOWERS=0
            echo "First data point - setting daily deltas to 0"
          fi

          # Clone eslint repo to count plugins and rules dynamically
          git clone --depth 1 https://github.com/ofri-peretz/eslint.git /tmp/eslint 2>/dev/null || true

          # Excluded plugins (matches NPM_CONFIG.excludedPackages)
          EXCLUDED_PLUGINS="eslint-plugin-mcp eslint-plugin-llm-optimized eslint-plugin-llm eslint-plugin-mcp-optimized cli eslint-devkit"

          # Count plugins (directories starting with eslint-plugin-*)
          PLUGIN_COUNT=0
          RULES_COUNT=0
          for dir in /tmp/eslint/packages/eslint-plugin-*/; do
            if [ -d "$dir" ]; then
              plugin_name=$(basename "$dir")
              # Check if plugin is excluded
              is_excluded=false
              for excluded in $EXCLUDED_PLUGINS; do
                if [ "$plugin_name" = "$excluded" ]; then
                  is_excluded=true
                  break
                fi
              done
              if [ "$is_excluded" = "false" ]; then
                PLUGIN_COUNT=$((PLUGIN_COUNT + 1))
                # Count rules in this plugin (directories in src/rules/, excluding __tests__)
                if [ -d "$dir/src/rules" ]; then
                  rule_count=$(find "$dir/src/rules" -maxdepth 1 -type d ! -name "__tests__" ! -name "rules" | wc -l)
                  RULES_COUNT=$((RULES_COUNT + rule_count))
                fi
              fi
            fi
          done

          # Fallback if git clone failed
          [ $PLUGIN_COUNT -eq 0 ] && PLUGIN_COUNT=11
          [ $RULES_COUNT -eq 0 ] && RULES_COUNT=216

          echo "Counted $PLUGIN_COUNT plugins and $RULES_COUNT rules"

          # Fetch test coverage from Codecov API for eslint repo
          if [ -n "$CODECOV_TOKEN" ]; then
            CODECOV_RESPONSE=$(curl -s -H "Authorization: Bearer $CODECOV_TOKEN" \
              "https://codecov.io/api/v2/github/ofri-peretz/repos/eslint/coverage" 2>/dev/null || echo "{}")
            TEST_COVERAGE=$(echo $CODECOV_RESPONSE | jq '.coverage // 90' | cut -d'.' -f1)
          else
            TEST_COVERAGE=90
          fi
          [ -z "$TEST_COVERAGE" ] && TEST_COVERAGE=90
          echo "Test coverage: $TEST_COVERAGE%"

          # Create snapshot JSON with both cumulative totals and daily deltas
          cat > .data/snapshots/$DATE.json << EOF
          {
            "date": "$DATE",
            "npm": {
              "totalDownloads": $TOTAL_DOWNLOADS,
              "dailyDownloads": $DAILY_DOWNLOADS,
              "packageCount": $PACKAGE_COUNT
            },
            "github": {
              "stars": $GH_STARS,
              "followers": $GH_FOLLOWERS,
              "contributions": $GH_CONTRIBUTIONS,
              "dailyContributions": $DAILY_CONTRIBUTIONS,
              "commits": $GH_COMMITS,
              "dailyCommits": $DAILY_COMMITS
            },
            "devto": {
              "views": $DEVTO_VIEWS,
              "dailyViews": $DAILY_VIEWS,
              "followers": $DEVTO_FOLLOWERS,
              "dailyFollowers": $DAILY_FOLLOWERS,
              "reactions": $DEVTO_REACTIONS,
              "dailyReactions": $DAILY_REACTIONS,
              "comments": $DEVTO_COMMENTS,
              "dailyComments": $DAILY_COMMENTS,
              "articles": $DEVTO_ARTICLE_COUNT
            },
            "ecosystem": {
              "packages": $PACKAGE_COUNT,
              "plugins": $PLUGIN_COUNT,
              "rules": $RULES_COUNT,
              "owaspCoverage": 100,
              "testCoverage": $TEST_COVERAGE
            }
          }
          EOF

          echo "Snapshot created for $DATE"
          cat .data/snapshots/$DATE.json

          # Update aggregation.json (single compact file containing all snapshots for fast loading)
          AGGREGATION_FILE=".data/snapshots/aggregation.json"

          # BACKUP: Create timestamped backup before modification (enables recovery from git history)
          if [ -f "$AGGREGATION_FILE" ]; then
            BACKUP_FILE=".data/snapshots/aggregation.backup.$(date +%Y%m%d).json"
            cp "$AGGREGATION_FILE" "$BACKUP_FILE"
            echo "ðŸ“¦ Backup created: $BACKUP_FILE"
          fi

          if [ -f "$AGGREGATION_FILE" ]; then
            # Read existing aggregation, remove entry for today if exists, add new one
            # Use -c for compact output (minified JSON)
            jq -c --slurpfile new .data/snapshots/$DATE.json \
              '[.[] | select(.date != "'"$DATE"'")] + $new | sort_by(.date) | .[-365:]' \
              "$AGGREGATION_FILE" > /tmp/aggregation.json && mv /tmp/aggregation.json "$AGGREGATION_FILE"
          else
            # SAFEGUARD: If aggregation.json is missing, rebuild from ALL individual snapshots
            # This prevents data loss - we never create a new file with only today's data
            echo "âš ï¸  aggregation.json missing - rebuilding from all individual snapshots"
            jq -c -s 'sort_by(.date) | .[-365:]' .data/snapshots/[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9].json > "$AGGREGATION_FILE"
          fi
          echo "Aggregation updated: $(jq 'length' $AGGREGATION_FILE) snapshots, $(wc -c < $AGGREGATION_FILE) bytes"

      - name: Commit and push snapshot
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add -f .data/snapshots/
          git diff --staged --quiet || git commit -m "chore: daily metrics snapshot $(date +%Y-%m-%d)"
          git push
